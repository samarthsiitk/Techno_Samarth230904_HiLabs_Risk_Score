{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c386113a955411eb5447175ed205f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55aebfb203174237b47ff81f607d0b35",
              "IPY_MODEL_8e8f00a274e64ac0b50b9bcce26e6831",
              "IPY_MODEL_e7fdcd696d7d4688bfaa20cefb6d04ff"
            ],
            "layout": "IPY_MODEL_509bb44e026e47b9aa5d0afa0dee2712"
          }
        },
        "55aebfb203174237b47ff81f607d0b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbde79e1b074e738cfd62a6b44f4651",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ba3dede34239443590a0f82f349a7663",
            "value": "Bestâ€‡trial:â€‡22.â€‡Bestâ€‡value:â€‡-0.837893:â€‡100%"
          }
        },
        "8e8f00a274e64ac0b50b9bcce26e6831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b5b4d37a2941f2aef8171e78984358",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0f10687c8b045ec9cef2b7db30e99b3",
            "value": 30
          }
        },
        "e7fdcd696d7d4688bfaa20cefb6d04ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa12c79fd68241e9ac63a98d253cfc88",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_10d792ef4b7841b4a6c451ff20c50f6c",
            "value": "â€‡30/30â€‡[33:31&lt;00:00,â€‡83.34s/it]"
          }
        },
        "509bb44e026e47b9aa5d0afa0dee2712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbde79e1b074e738cfd62a6b44f4651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3dede34239443590a0f82f349a7663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b5b4d37a2941f2aef8171e78984358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f10687c8b045ec9cef2b7db30e99b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa12c79fd68241e9ac63a98d253cfc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d792ef4b7841b4a6c451ff20c50f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSTyfrd5kKin",
        "outputId": "34fa0196-674b-405a-fea9-3d38e7fb16a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.16-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from lazypredict) (8.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lazypredict) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from lazypredict) (1.5.2)\n",
            "Collecting pytest-runner (from lazypredict)\n",
            "  Downloading pytest_runner-6.0.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting mlflow>=2.0.0 (from lazypredict)\n",
            "  Downloading mlflow-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Collecting mlflow-skinny==3.5.1 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading mlflow_skinny-3.5.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.5.1 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading mlflow_tracing-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->lazypredict) (3.1.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->lazypredict) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow>=2.0.0->lazypredict)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->lazypredict) (18.1.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict)\n",
            "  Downloading databricks_sdk-0.71.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.120.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (1.37.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (2.11.10)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (1.2.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.38.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow>=2.0.0->lazypredict) (2.0.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (3.0.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.0.0->lazypredict)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.0.0->lazypredict)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow>=2.0.0->lazypredict) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.49.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.4.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=2.0.0->lazypredict) (0.6.1)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazypredict-0.2.16-py2.py3-none-any.whl (14 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.5.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.5.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.5.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading pytest_runner-6.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.71.0-py3-none-any.whl (752 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m752.6/752.6 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: pytest-runner, gunicorn, graphql-core, colorlog, graphql-relay, docker, optuna, graphene, Flask-CORS, databricks-sdk, catboost, mlflow-tracing, mlflow-skinny, mlflow, lazypredict\n",
            "Successfully installed Flask-CORS-6.0.1 catboost-1.2.8 colorlog-6.10.1 databricks-sdk-0.71.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 lazypredict-0.2.16 mlflow-3.5.1 mlflow-skinny-3.5.1 mlflow-tracing-3.5.1 optuna-4.5.0 pytest-runner-6.0.1\n",
            "âœ… Enhanced setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "!pip install lightgbm xgboost catboost lazypredict scikit-learn scipy tensorflow optuna\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Enhanced setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TRAIN datasets\n",
        "print(\"ðŸ“¥ Loading train datasets...\")\n",
        "train_patient = pd.read_csv('patient_train.csv')  # Use your actual train filenames\n",
        "train_risk = pd.read_csv('risk_train.csv')\n",
        "train_diagnosis = pd.read_csv('diagnosis_train.csv')\n",
        "train_visit = pd.read_csv('visit_train.csv')\n",
        "train_care = pd.read_csv('care_train.csv')\n",
        "\n",
        "# Load TEST datasets\n",
        "print(\"ðŸ“¥ Loading test datasets...\")\n",
        "test_patient = pd.read_csv('patient.csv')\n",
        "test_diagnosis = pd.read_csv('diagnosis.csv')\n",
        "test_visit = pd.read_csv('visit.csv')\n",
        "test_care = pd.read_csv('care.csv')\n",
        "\n",
        "print(f\"Train: {len(train_patient)} patients, {len(train_risk)} risk scores\")\n",
        "print(f\"Test: {len(test_patient)} patients\")\n",
        "print(\"âœ… Data loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzZwmpYRlHeX",
        "outputId": "aff7e016-4b10-42ba-e3bc-4d660a318a88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading train datasets...\n",
            "ðŸ“¥ Loading test datasets...\n",
            "Train: 8000 patients, 8000 risk scores\n",
            "Test: 2001 patients\n",
            "âœ… Data loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_feature_engineering(patient_df, diagnosis_df, visit_df, care_df):\n",
        "    print(\"ðŸ› ï¸ Engineering enhanced features...\")\n",
        "    features_df = patient_df.copy()\n",
        "\n",
        "    # Convert boolean flags\n",
        "    features_df['hot_spotter_readmission_flag'] = (features_df['hot_spotter_readmission_flag'] == 't').astype(int)\n",
        "    features_df['hot_spotter_chronic_flag'] = (features_df['hot_spotter_chronic_flag'] == 't').astype(int)\n",
        "\n",
        "    # Enhanced age features\n",
        "    features_df['age_group'] = pd.cut(features_df['age'], bins=[0, 30, 50, 70, 100], labels=[1, 2, 3, 4]).astype(int)\n",
        "    features_df['is_elderly'] = (features_df['age'] >= 65).astype(int)\n",
        "    features_df['is_young'] = (features_df['age'] <= 30).astype(int)\n",
        "\n",
        "    # Hot spotter duration (if available)\n",
        "    try:\n",
        "        features_df['hot_spotter_identified_at'] = pd.to_datetime(features_df['hot_spotter_identified_at'], errors='coerce')\n",
        "        current_date = pd.to_datetime('2025-11-02')\n",
        "        features_df['days_since_hot_spot'] = (current_date - features_df['hot_spotter_identified_at']).dt.days\n",
        "        features_df['days_since_hot_spot'] = features_df['days_since_hot_spot'].fillna(9999)\n",
        "        features_df['is_recent_hot_spotter'] = (features_df['days_since_hot_spot'] <= 90).astype(int)\n",
        "    except:\n",
        "        features_df['days_since_hot_spot'] = 0\n",
        "        features_df['is_recent_hot_spotter'] = 0\n",
        "\n",
        "    # DIAGNOSIS FEATURES\n",
        "    if len(diagnosis_df) > 0:\n",
        "        diag_agg = diagnosis_df.groupby('patient_id').agg({\n",
        "            'condition_name': 'count',\n",
        "            'is_chronic': lambda x: (x == 't').sum(),\n",
        "        }).rename(columns={'condition_name': 'total_conditions', 'is_chronic': 'chronic_conditions'})\n",
        "\n",
        "        # Condition complexity\n",
        "        condition_types = diagnosis_df.groupby('patient_id')['condition_name'].apply(\n",
        "            lambda x: len(set(x))\n",
        "        ).rename('unique_conditions')\n",
        "        diag_agg = diag_agg.join(condition_types)\n",
        "\n",
        "        # Disease severity indicators\n",
        "        high_risk_conditions = ['CANCER', 'DIABETES', 'HYPERTENSION']\n",
        "        for condition in high_risk_conditions:\n",
        "            has_condition = diagnosis_df[diagnosis_df['condition_name'] == condition].groupby('patient_id').size() > 0\n",
        "            diag_agg[f'has_{condition.lower()}'] = has_condition.astype(int)\n",
        "\n",
        "        # Comorbidity score\n",
        "        diag_agg['comorbidity_score'] = diag_agg['chronic_conditions'] * diag_agg['unique_conditions']\n",
        "\n",
        "    else:\n",
        "        diag_agg = pd.DataFrame(index=patient_df['patient_id'])\n",
        "        diag_agg['total_conditions'] = 0\n",
        "        diag_agg['chronic_conditions'] = 0\n",
        "        diag_agg['unique_conditions'] = 0\n",
        "        diag_agg['comorbidity_score'] = 0\n",
        "        for condition in ['cancer', 'diabetes', 'hypertension']:\n",
        "            diag_agg[f'has_{condition}'] = 0\n",
        "\n",
        "    # VISIT FEATURES\n",
        "    if len(visit_df) > 0:\n",
        "        visit_agg = visit_df.groupby('patient_id').agg({\n",
        "            'visit_type': 'count',\n",
        "            'readmsn_ind': lambda x: (x == 't').sum(),\n",
        "        }).rename(columns={'visit_type': 'total_visits', 'readmsn_ind': 'readmissions'})\n",
        "\n",
        "        # Visit type analysis\n",
        "        for vtype in ['ER', 'URGENT CARE', 'INPATIENT']:\n",
        "            visit_counts = visit_df[visit_df['visit_type'] == vtype].groupby('patient_id').size()\n",
        "            visit_agg[f'{vtype.lower().replace(\" \", \"_\")}_visits'] = visit_counts.fillna(0)\n",
        "\n",
        "        # Emergency patterns\n",
        "        visit_agg['emergency_visits'] = visit_agg['er_visits'] + visit_agg['urgent_care_visits']\n",
        "        visit_agg['emergency_ratio'] = visit_agg['emergency_visits'] / (visit_agg['total_visits'] + 1)\n",
        "        visit_agg['readmission_rate'] = visit_agg['readmissions'] / (visit_agg['total_visits'] + 1)\n",
        "\n",
        "        # Visit intensity\n",
        "        visit_agg['is_frequent_visitor'] = (visit_agg['total_visits'] >= 5).astype(int)\n",
        "        visit_agg['has_readmissions'] = (visit_agg['readmissions'] > 0).astype(int)\n",
        "\n",
        "    else:\n",
        "        visit_agg = pd.DataFrame(index=patient_df['patient_id'])\n",
        "        visit_cols = ['total_visits', 'readmissions', 'er_visits', 'urgent_care_visits',\n",
        "                     'inpatient_visits', 'emergency_visits', 'emergency_ratio', 'readmission_rate',\n",
        "                     'is_frequent_visitor', 'has_readmissions']\n",
        "        for col in visit_cols:\n",
        "            visit_agg[col] = 0\n",
        "\n",
        "    # CARE FEATURES\n",
        "    if len(care_df) > 0:\n",
        "        care_agg = care_df.groupby('patient_id').agg({\n",
        "            'care_gap_ind': lambda x: (x == 't').sum(),\n",
        "            'msrmnt_value': ['mean', 'max', 'std'],\n",
        "            'msrmnt_type': 'count'\n",
        "        })\n",
        "        care_agg.columns = ['care_gaps', 'avg_measurement', 'max_measurement', 'std_measurement', 'total_care_events']\n",
        "        care_agg['std_measurement'] = care_agg['std_measurement'].fillna(0)\n",
        "\n",
        "        # Care quality indicators\n",
        "        care_agg['care_gap_ratio'] = care_agg['care_gaps'] / (care_agg['total_care_events'] + 1)\n",
        "        care_agg['care_adherence'] = 1 - care_agg['care_gap_ratio']\n",
        "        care_agg['has_care_gaps'] = (care_agg['care_gaps'] > 0).astype(int)\n",
        "\n",
        "        # Lab value risk (assuming HbA1c and BP measurements)\n",
        "        care_agg['abnormal_lab_risk'] = 0\n",
        "        care_agg.loc[care_agg['max_measurement'] > 7, 'abnormal_lab_risk'] = 1  # HbA1c > 7\n",
        "        care_agg.loc[care_agg['max_measurement'] > 140, 'abnormal_lab_risk'] = 2  # BP > 140\n",
        "\n",
        "    else:\n",
        "        care_agg = pd.DataFrame(index=patient_df['patient_id'])\n",
        "        care_cols = ['care_gaps', 'avg_measurement', 'max_measurement', 'std_measurement',\n",
        "                    'total_care_events', 'care_gap_ratio', 'care_adherence', 'has_care_gaps', 'abnormal_lab_risk']\n",
        "        for col in care_cols:\n",
        "            care_agg[col] = 0\n",
        "\n",
        "    # MERGE ALL FEATURES\n",
        "    features_df = features_df.set_index('patient_id')\n",
        "    features_df = features_df.join(diag_agg, how='left')\n",
        "    features_df = features_df.join(visit_agg, how='left')\n",
        "    features_df = features_df.join(care_agg, how='left')\n",
        "    features_df = features_df.fillna(0)\n",
        "\n",
        "    # ADVANCED INTERACTION FEATURES\n",
        "    features_df['age_chronic_score'] = features_df['age'] * features_df['chronic_conditions']\n",
        "    features_df['visit_care_ratio'] = features_df['total_visits'] / (features_df['total_care_events'] + 1)\n",
        "    features_df['chronic_burden'] = features_df['chronic_conditions'] / (features_df['total_conditions'] + 1)\n",
        "    features_df['risk_multiplier'] = features_df['age_group'] * (features_df['chronic_conditions'] + 1) * (features_df['emergency_ratio'] + 0.1)\n",
        "    features_df['care_utilization_score'] = (features_df['total_visits'] + features_df['total_care_events']) / features_df['age']\n",
        "    features_df['health_complexity'] = features_df['comorbidity_score'] * features_df['emergency_ratio'] * (features_df['care_gap_ratio'] + 0.1)\n",
        "\n",
        "    features_df = features_df.reset_index()\n",
        "    print(f\"âœ… Created {len(features_df.columns)-1} enhanced features\")\n",
        "    return features_df\n",
        "\n",
        "# Generate enhanced features\n",
        "X_train_feat = enhanced_feature_engineering(train_patient, train_diagnosis, train_visit, train_care)\n",
        "X_test_feat = enhanced_feature_engineering(test_patient, test_diagnosis, test_visit, test_care)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9V3ODFLlRKK",
        "outputId": "69870535-b86a-444b-9f58-274fce730824"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ› ï¸ Engineering enhanced features...\n",
            "âœ… Created 41 enhanced features\n",
            "ðŸ› ï¸ Engineering enhanced features...\n",
            "âœ… Created 41 enhanced features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_text_features(train_diagnosis, test_diagnosis, train_visit, test_visit):\n",
        "    print(\"ðŸ“ Processing advanced text features...\")\n",
        "\n",
        "    def get_enhanced_patient_text(diagnosis_df, visit_df, patient_ids):\n",
        "        patient_texts = []\n",
        "        for pid in patient_ids:\n",
        "            texts = []\n",
        "\n",
        "            # Diagnosis descriptions with weights\n",
        "            if len(diagnosis_df) > 0:\n",
        "                patient_diag = diagnosis_df[diagnosis_df['patient_id'] == pid]\n",
        "                if not patient_diag.empty:\n",
        "                    # Weight chronic conditions more heavily\n",
        "                    chronic_text = patient_diag[patient_diag['is_chronic'] == 't']['condition_description'].fillna('').astype(str)\n",
        "                    acute_text = patient_diag[patient_diag['is_chronic'] == 'f']['condition_description'].fillna('').astype(str)\n",
        "\n",
        "                    if not chronic_text.empty:\n",
        "                        texts.append(' '.join(chronic_text) + ' ' + ' '.join(chronic_text))  # Double weight\n",
        "                    if not acute_text.empty:\n",
        "                        texts.append(' '.join(acute_text))\n",
        "\n",
        "            # Visit diagnoses\n",
        "            if len(visit_df) > 0:\n",
        "                patient_visits = visit_df[visit_df['patient_id'] == pid]\n",
        "                if not patient_visits.empty:\n",
        "                    visit_text = ' '.join(patient_visits['prncpl_diag_nm'].fillna('').astype(str))\n",
        "                    texts.append(visit_text)\n",
        "\n",
        "            combined = ' '.join(texts) if texts else 'no_medical_history'\n",
        "            patient_texts.append(combined)\n",
        "\n",
        "        return patient_texts\n",
        "\n",
        "    # Get enhanced text\n",
        "    train_texts = get_enhanced_patient_text(train_diagnosis, train_visit, train_patient['patient_id'])\n",
        "    test_texts = get_enhanced_patient_text(test_diagnosis, test_visit, test_patient['patient_id'])\n",
        "\n",
        "    # Enhanced TF-IDF with multiple configurations\n",
        "    # Word-level TF-IDF\n",
        "    tfidf_word = TfidfVectorizer(\n",
        "        max_features=1200,\n",
        "        ngram_range=(1, 3),\n",
        "        stop_words='english',\n",
        "        min_df=2,\n",
        "        max_df=0.95,\n",
        "        analyzer='word'\n",
        "    )\n",
        "\n",
        "    # Character-level TF-IDF for medical terms\n",
        "    tfidf_char = TfidfVectorizer(\n",
        "        max_features=800,\n",
        "        ngram_range=(3, 6),\n",
        "        analyzer='char',\n",
        "        min_df=2,\n",
        "        max_df=0.98\n",
        "    )\n",
        "\n",
        "    # Fit and transform\n",
        "    X_text_word_train = tfidf_word.fit_transform(train_texts)\n",
        "    X_text_word_test = tfidf_word.transform(test_texts)\n",
        "\n",
        "    X_text_char_train = tfidf_char.fit_transform(train_texts)\n",
        "    X_text_char_test = tfidf_char.transform(test_texts)\n",
        "\n",
        "    # Combine word and character features\n",
        "    X_text_train = hstack([X_text_word_train, X_text_char_train])\n",
        "    X_text_test = hstack([X_text_word_test, X_text_char_test])\n",
        "\n",
        "    print(f\"âœ… Created {X_text_train.shape[1]} advanced text features (word + char)\")\n",
        "    return X_text_train, X_text_test\n",
        "\n",
        "# Create advanced text features\n",
        "X_text_train, X_text_test = advanced_text_features(train_diagnosis, test_diagnosis, train_visit, test_visit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmpDDCKblTEC",
        "outputId": "f445381c-b083-4fa5-859f-90aa058cd305"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Processing advanced text features...\n",
            "âœ… Created 2000 advanced text features (word + char)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Prepare numerical features and fix data types\n",
        "feature_cols = [col for col in X_train_feat.columns if col not in ['patient_id']]\n",
        "print(\"ðŸ”§ Advanced data preparation...\")\n",
        "\n",
        "X_train_df = X_train_feat[feature_cols].copy()\n",
        "X_test_df = X_test_feat[feature_cols].copy()\n",
        "\n",
        "# Convert object columns to numeric\n",
        "label_encoders = {}\n",
        "for col in X_train_df.columns:\n",
        "    if X_train_df[col].dtype == 'object':\n",
        "        print(f\"Converting {col} from object to numeric\")\n",
        "        le = LabelEncoder()\n",
        "        combined_values = pd.concat([X_train_df[col], X_test_df[col]]).astype(str)\n",
        "        le.fit(combined_values)\n",
        "\n",
        "        X_train_df[col] = le.transform(X_train_df[col].astype(str))\n",
        "        X_test_df[col] = le.transform(X_test_df[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# Convert to float64\n",
        "X_train_df = X_train_df.astype('float64')\n",
        "X_test_df = X_test_df.astype('float64')\n",
        "\n",
        "# Standard scaling for numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_df)\n",
        "X_test_scaled = scaler.transform(X_test_df)\n",
        "\n",
        "# Convert text features to dense\n",
        "X_text_train_dense = X_text_train.toarray()\n",
        "X_text_test_dense = X_text_test.toarray()\n",
        "\n",
        "# Combine scaled numerical + text features\n",
        "X_train_combined = np.hstack([X_train_scaled, X_text_train_dense])\n",
        "X_test_combined = np.hstack([X_test_scaled, X_text_test_dense])\n",
        "\n",
        "# Target variable with log transformation\n",
        "y_train = train_risk.set_index('patient_id').loc[X_train_feat['patient_id'], 'risk_score'].values\n",
        "y_train_log = np.log1p(y_train)  # Log transform for better distribution\n",
        "\n",
        "print(f\"Numerical features: {X_train_scaled.shape[1]}\")\n",
        "print(f\"Text features: {X_text_train_dense.shape[1]}\")\n",
        "print(f\"Final feature matrix: {X_train_combined.shape}\")\n",
        "print(f\"Target statistics: Mean={y_train.mean():.2f}, Std={y_train.std():.2f}\")\n",
        "print(\"âœ… Advanced data preparation complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6luRdylXXh",
        "outputId": "f21b4465-1b23-4ca5-92b2-db7220b9a9f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Advanced data preparation...\n",
            "Converting hot_spotter_identified_at from object to numeric\n",
            "Numerical features: 41\n",
            "Text features: 2000\n",
            "Final feature matrix: (8000, 2041)\n",
            "Target statistics: Mean=1.68, Std=2.52\n",
            "âœ… Advanced data preparation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_healthcare_nn(input_dim):\n",
        "    print(\"ðŸ§  Creating healthcare deep learning model...\")\n",
        "\n",
        "    # Input layer\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # Feature extraction with dropout and batch norm\n",
        "    x = layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # Healthcare-specific layers\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Final prediction layer\n",
        "    outputs = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # Advanced optimizer with learning rate scheduling\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='huber',  # Robust to outliers\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and train deep learning model\n",
        "print(\"ðŸš€ Training deep learning model...\")\n",
        "nn_model = create_healthcare_nn(X_train_combined.shape[1])\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001\n",
        ")\n",
        "\n",
        "# Train on log-transformed target\n",
        "history = nn_model.fit(\n",
        "    X_train_combined, y_train_log,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predictions (transform back from log scale)\n",
        "nn_predictions = np.expm1(nn_model.predict(X_test_combined, verbose=0)).flatten()\n",
        "print(\"âœ… Deep learning model trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm-Ei_ealcue",
        "outputId": "c44d0e4e-6dfb-4e76-9bf5-b7c8c0740f90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training deep learning model...\n",
            "ðŸ§  Creating healthcare deep learning model...\n",
            "Epoch 1/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 2.2007 - mae: 0.8187 - val_loss: 1.3893 - val_mae: 0.3869 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3416 - mae: 0.4690 - val_loss: 1.0312 - val_mae: 0.3448 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9980 - mae: 0.3958 - val_loss: 0.8072 - val_mae: 0.3211 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7978 - mae: 0.3771 - val_loss: 0.6539 - val_mae: 0.3236 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6499 - mae: 0.3441 - val_loss: 0.5571 - val_mae: 0.3072 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5398 - mae: 0.3195 - val_loss: 0.4713 - val_mae: 0.3084 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4563 - mae: 0.3071 - val_loss: 0.3915 - val_mae: 0.3040 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3856 - mae: 0.2974 - val_loss: 0.3307 - val_mae: 0.2881 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3323 - mae: 0.2954 - val_loss: 0.2860 - val_mae: 0.2867 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2833 - mae: 0.2885 - val_loss: 0.2406 - val_mae: 0.2619 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2412 - mae: 0.2804 - val_loss: 0.2085 - val_mae: 0.2707 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2123 - mae: 0.2797 - val_loss: 0.1811 - val_mae: 0.2615 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1829 - mae: 0.2751 - val_loss: 0.1610 - val_mae: 0.2654 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1632 - mae: 0.2717 - val_loss: 0.1430 - val_mae: 0.2712 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1457 - mae: 0.2682 - val_loss: 0.1273 - val_mae: 0.2702 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1311 - mae: 0.2682 - val_loss: 0.1177 - val_mae: 0.2541 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1199 - mae: 0.2610 - val_loss: 0.1047 - val_mae: 0.2521 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1137 - mae: 0.2643 - val_loss: 0.1011 - val_mae: 0.2556 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1089 - mae: 0.2665 - val_loss: 0.0947 - val_mae: 0.2563 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0993 - mae: 0.2578 - val_loss: 0.0885 - val_mae: 0.2480 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0965 - mae: 0.2627 - val_loss: 0.0865 - val_mae: 0.2485 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0920 - mae: 0.2600 - val_loss: 0.0843 - val_mae: 0.2531 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0898 - mae: 0.2571 - val_loss: 0.0839 - val_mae: 0.2538 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0854 - mae: 0.2544 - val_loss: 0.0841 - val_mae: 0.2571 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0867 - mae: 0.2592 - val_loss: 0.0786 - val_mae: 0.2504 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0817 - mae: 0.2528 - val_loss: 0.0798 - val_mae: 0.2575 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0780 - mae: 0.2501 - val_loss: 0.0801 - val_mae: 0.2545 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0804 - mae: 0.2538 - val_loss: 0.0766 - val_mae: 0.2488 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0778 - mae: 0.2503 - val_loss: 0.0764 - val_mae: 0.2464 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0782 - mae: 0.2529 - val_loss: 0.0738 - val_mae: 0.2488 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0765 - mae: 0.2515 - val_loss: 0.0745 - val_mae: 0.2555 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0774 - mae: 0.2513 - val_loss: 0.0721 - val_mae: 0.2464 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.2432 - val_loss: 0.0748 - val_mae: 0.2469 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0768 - mae: 0.2505 - val_loss: 0.0736 - val_mae: 0.2490 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0766 - mae: 0.2514 - val_loss: 0.0744 - val_mae: 0.2455 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.2459 - val_loss: 0.0774 - val_mae: 0.2574 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0757 - mae: 0.2514 - val_loss: 0.0706 - val_mae: 0.2457 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0720 - mae: 0.2488 - val_loss: 0.0718 - val_mae: 0.2537 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0748 - mae: 0.2521 - val_loss: 0.0787 - val_mae: 0.2533 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0774 - mae: 0.2542 - val_loss: 0.0722 - val_mae: 0.2454 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0751 - mae: 0.2521 - val_loss: 0.0716 - val_mae: 0.2527 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0741 - mae: 0.2512 - val_loss: 0.0706 - val_mae: 0.2487 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0691 - mae: 0.2435 - val_loss: 0.0654 - val_mae: 0.2507 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0661 - mae: 0.2457 - val_loss: 0.0669 - val_mae: 0.2565 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0664 - mae: 0.2445 - val_loss: 0.0636 - val_mae: 0.2475 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0658 - mae: 0.2430 - val_loss: 0.0633 - val_mae: 0.2437 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0648 - mae: 0.2443 - val_loss: 0.0638 - val_mae: 0.2436 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0682 - mae: 0.2462 - val_loss: 0.0672 - val_mae: 0.2536 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.2438 - val_loss: 0.0646 - val_mae: 0.2464 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0649 - mae: 0.2444 - val_loss: 0.0680 - val_mae: 0.2527 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0682 - mae: 0.2495 - val_loss: 0.0695 - val_mae: 0.2541 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0660 - mae: 0.2461 - val_loss: 0.0633 - val_mae: 0.2453 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0600 - mae: 0.2363 - val_loss: 0.0612 - val_mae: 0.2438 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0639 - mae: 0.2452 - val_loss: 0.0642 - val_mae: 0.2493 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0631 - mae: 0.2427 - val_loss: 0.0623 - val_mae: 0.2446 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0613 - mae: 0.2391 - val_loss: 0.0634 - val_mae: 0.2465 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0612 - mae: 0.2385 - val_loss: 0.0635 - val_mae: 0.2431 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0632 - mae: 0.2395 - val_loss: 0.0628 - val_mae: 0.2448 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - mae: 0.2356 - val_loss: 0.0612 - val_mae: 0.2426 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0593 - mae: 0.2366 - val_loss: 0.0620 - val_mae: 0.2441 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0614 - mae: 0.2411 - val_loss: 0.0604 - val_mae: 0.2413 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0601 - mae: 0.2367 - val_loss: 0.0605 - val_mae: 0.2415 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0560 - mae: 0.2278 - val_loss: 0.0617 - val_mae: 0.2461 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0581 - mae: 0.2333 - val_loss: 0.0608 - val_mae: 0.2435 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0603 - mae: 0.2396 - val_loss: 0.0626 - val_mae: 0.2435 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0588 - mae: 0.2369 - val_loss: 0.0617 - val_mae: 0.2434 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0561 - mae: 0.2298 - val_loss: 0.0618 - val_mae: 0.2442 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0579 - mae: 0.2337 - val_loss: 0.0615 - val_mae: 0.2448 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0555 - mae: 0.2292 - val_loss: 0.0614 - val_mae: 0.2409 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.2314 - val_loss: 0.0614 - val_mae: 0.2427 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0589 - mae: 0.2348 - val_loss: 0.0623 - val_mae: 0.2473 - learning_rate: 1.0000e-04\n",
            "âœ… Deep learning model trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimized_models(X_train, y_train, X_test, use_optuna=True):\n",
        "    print(\"ðŸ”¥ Training optimized ensemble models...\")\n",
        "\n",
        "    models = {}\n",
        "    predictions = {}\n",
        "\n",
        "    if use_optuna:\n",
        "        print(\"ðŸŽ¯ Optimizing LightGBM with Optuna...\")\n",
        "\n",
        "        def lgb_objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.15),\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "                'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)\n",
        "            }\n",
        "\n",
        "            model = LGBMRegressor(**params, random_state=42, n_jobs=-1, verbose=-1)\n",
        "            scores = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
        "            return scores.mean()\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lgb_objective, n_trials=30, show_progress_bar=True)\n",
        "\n",
        "        best_lgb_params = study.best_params\n",
        "        print(f\"Best LGB params: {best_lgb_params}\")\n",
        "    else:\n",
        "        best_lgb_params = {\n",
        "            'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50,\n",
        "            'max_depth': 10, 'min_child_samples': 20\n",
        "        }\n",
        "\n",
        "    # 1. Optimized LightGBM\n",
        "    print(\"Training optimized LightGBM...\")\n",
        "    lgb_model = LGBMRegressor(**best_lgb_params, random_state=42, n_jobs=-1, verbose=-1)\n",
        "    lgb_model.fit(X_train, y_train)\n",
        "    models['lgb'] = lgb_model\n",
        "    predictions['lgb'] = lgb_model.predict(X_test)\n",
        "\n",
        "    # 2. Enhanced XGBoost\n",
        "    print(\"Training enhanced XGBoost...\")\n",
        "    xgb_model = XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=8,\n",
        "        min_child_weight=3,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=1,\n",
        "        reg_lambda=1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    models['xgb'] = xgb_model\n",
        "    predictions['xgb'] = xgb_model.predict(X_test)\n",
        "\n",
        "    # 3. Enhanced CatBoost\n",
        "    print(\"Training enhanced CatBoost...\")\n",
        "    cat_model = CatBoostRegressor(\n",
        "        iterations=1000,\n",
        "        learning_rate=0.05,\n",
        "        depth=8,\n",
        "        l2_leaf_reg=5,\n",
        "        bagging_temperature=0.2,\n",
        "        random_strength=0.2,\n",
        "        bootstrap_type='Bernoulli',\n",
        "        subsample=0.8,\n",
        "        random_seed=42,\n",
        "        verbose=False\n",
        "    )\n",
        "    cat_model.fit(X_train, y_train)\n",
        "    models['cat'] = cat_model\n",
        "    predictions['cat'] = cat_model.predict(X_test)\n",
        "\n",
        "    # 4. Log-transformed LightGBM\n",
        "    print(\"Training log-scale LightGBM...\")\n",
        "    lgb_log_model = LGBMRegressor(\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.08,\n",
        "        num_leaves=60,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "    lgb_log_model.fit(X_train, y_train_log)\n",
        "    models['lgb_log'] = lgb_log_model\n",
        "    predictions['lgb_log'] = np.expm1(lgb_log_model.predict(X_test))\n",
        "\n",
        "    return models, predictions\n",
        "\n",
        "# Train optimized models\n",
        "models, predictions = create_optimized_models(X_train_combined, y_train, X_test_combined, use_optuna=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c386113a955411eb5447175ed205f24",
            "55aebfb203174237b47ff81f607d0b35",
            "8e8f00a274e64ac0b50b9bcce26e6831",
            "e7fdcd696d7d4688bfaa20cefb6d04ff",
            "509bb44e026e47b9aa5d0afa0dee2712",
            "abbde79e1b074e738cfd62a6b44f4651",
            "ba3dede34239443590a0f82f349a7663",
            "a7b5b4d37a2941f2aef8171e78984358",
            "d0f10687c8b045ec9cef2b7db30e99b3",
            "fa12c79fd68241e9ac63a98d253cfc88",
            "10d792ef4b7841b4a6c451ff20c50f6c"
          ]
        },
        "id": "5iPN3XAvlfUj",
        "outputId": "53ed1397-3ce2-4e26-f5a9-b3af8ab40efd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-02 17:21:41,050] A new study created in memory with name: no-name-34632382-57ac-4756-ab6c-1fbc3155f06e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Training optimized ensemble models...\n",
            "ðŸŽ¯ Optimizing LightGBM with Optuna...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c386113a955411eb5447175ed205f24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-11-02 17:22:51,161] Trial 0 finished with value: -0.9217447941509381 and parameters: {'n_estimators': 1329, 'learning_rate': 0.11426792155790387, 'num_leaves': 77, 'max_depth': 10, 'min_child_samples': 96, 'subsample': 0.7129878663501872, 'colsample_bytree': 0.7095741153329543, 'reg_alpha': 8.965663104865278, 'reg_lambda': 1.7961210682448958}. Best is trial 0 with value: -0.9217447941509381.\n",
            "[I 2025-11-02 17:24:39,546] Trial 1 finished with value: -0.8576301332664308 and parameters: {'n_estimators': 1005, 'learning_rate': 0.052589427002681155, 'num_leaves': 77, 'max_depth': 15, 'min_child_samples': 12, 'subsample': 0.670142809800336, 'colsample_bytree': 0.8384003823883666, 'reg_alpha': 7.498267455614567, 'reg_lambda': 0.72736139109564}. Best is trial 1 with value: -0.8576301332664308.\n",
            "[I 2025-11-02 17:25:13,328] Trial 2 finished with value: -0.8543082572186959 and parameters: {'n_estimators': 637, 'learning_rate': 0.0413131569230209, 'num_leaves': 32, 'max_depth': 6, 'min_child_samples': 55, 'subsample': 0.8017685253203821, 'colsample_bytree': 0.9729100450249429, 'reg_alpha': 3.183994383883376, 'reg_lambda': 8.08247036710324}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:26:07,869] Trial 3 finished with value: -0.8921900777392167 and parameters: {'n_estimators': 840, 'learning_rate': 0.07053325318610622, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.9804557025303181, 'colsample_bytree': 0.9718432909115607, 'reg_alpha': 7.446221106969345, 'reg_lambda': 4.907278980812415}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:26:57,419] Trial 4 finished with value: -0.9100439306956859 and parameters: {'n_estimators': 917, 'learning_rate': 0.1404069998401319, 'num_leaves': 84, 'max_depth': 12, 'min_child_samples': 56, 'subsample': 0.8185681406836145, 'colsample_bytree': 0.6866565031797514, 'reg_alpha': 8.773896361861906, 'reg_lambda': 2.115093348485458}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:28:34,064] Trial 5 finished with value: -0.8799746683616667 and parameters: {'n_estimators': 1357, 'learning_rate': 0.03480688304340731, 'num_leaves': 56, 'max_depth': 11, 'min_child_samples': 95, 'subsample': 0.6571953409892167, 'colsample_bytree': 0.9620733609421682, 'reg_alpha': 7.853689496808509, 'reg_lambda': 6.7022743429904965}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:29:26,651] Trial 6 finished with value: -0.893236978522337 and parameters: {'n_estimators': 678, 'learning_rate': 0.1265216753598915, 'num_leaves': 82, 'max_depth': 15, 'min_child_samples': 35, 'subsample': 0.6427731183999074, 'colsample_bytree': 0.9274584682708568, 'reg_alpha': 9.024600075855467, 'reg_lambda': 2.1953648862857813}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:29:58,048] Trial 7 finished with value: -0.8679988279105495 and parameters: {'n_estimators': 597, 'learning_rate': 0.14300372737397818, 'num_leaves': 60, 'max_depth': 9, 'min_child_samples': 17, 'subsample': 0.9716633211103712, 'colsample_bytree': 0.7254404859603134, 'reg_alpha': 9.435325477967774, 'reg_lambda': 2.134679828116981}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:31:12,446] Trial 8 finished with value: -0.9406979287031767 and parameters: {'n_estimators': 1284, 'learning_rate': 0.1444081344303595, 'num_leaves': 76, 'max_depth': 12, 'min_child_samples': 91, 'subsample': 0.9313268786755393, 'colsample_bytree': 0.654058219983748, 'reg_alpha': 4.488110130010298, 'reg_lambda': 6.308375606270875}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:32:14,788] Trial 9 finished with value: -0.8767205840130798 and parameters: {'n_estimators': 1351, 'learning_rate': 0.03713937374281348, 'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 82, 'subsample': 0.973138042636015, 'colsample_bytree': 0.8080242204329072, 'reg_alpha': 9.548867803354044, 'reg_lambda': 5.656011786640544}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:32:33,250] Trial 10 finished with value: -0.8703235492647474 and parameters: {'n_estimators': 500, 'learning_rate': 0.08950051477886871, 'num_leaves': 22, 'max_depth': 5, 'min_child_samples': 61, 'subsample': 0.8210094793910186, 'colsample_bytree': 0.8772023160603479, 'reg_alpha': 0.5633767123789752, 'reg_lambda': 9.956316455944997}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:34:56,187] Trial 11 finished with value: -0.8720137217145085 and parameters: {'n_estimators': 1104, 'learning_rate': 0.05923378397382602, 'num_leaves': 100, 'max_depth': 15, 'min_child_samples': 13, 'subsample': 0.739848666262961, 'colsample_bytree': 0.8381243817287397, 'reg_alpha': 4.235688077332358, 'reg_lambda': 9.164483936716259}. Best is trial 2 with value: -0.8543082572186959.\n",
            "[I 2025-11-02 17:35:49,587] Trial 12 finished with value: -0.8469103179423577 and parameters: {'n_estimators': 1081, 'learning_rate': 0.022864181529585317, 'num_leaves': 59, 'max_depth': 6, 'min_child_samples': 36, 'subsample': 0.7606882377071734, 'colsample_bytree': 0.892443246915652, 'reg_alpha': 2.5426205071095964, 'reg_lambda': 0.011823046521845737}. Best is trial 12 with value: -0.8469103179423577.\n",
            "[I 2025-11-02 17:36:39,346] Trial 13 finished with value: -0.848715222330824 and parameters: {'n_estimators': 1153, 'learning_rate': 0.02270671923825735, 'num_leaves': 45, 'max_depth': 5, 'min_child_samples': 37, 'subsample': 0.8822476573736119, 'colsample_bytree': 0.9053410397796006, 'reg_alpha': 2.2984573019378485, 'reg_lambda': 8.037587088965605}. Best is trial 12 with value: -0.8469103179423577.\n",
            "[I 2025-11-02 17:37:48,917] Trial 14 finished with value: -0.8427647581068584 and parameters: {'n_estimators': 1148, 'learning_rate': 0.02334966727569169, 'num_leaves': 56, 'max_depth': 7, 'min_child_samples': 31, 'subsample': 0.8754189813500745, 'colsample_bytree': 0.8973969167168248, 'reg_alpha': 1.700578151141682, 'reg_lambda': 3.9546183968418585}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:38:51,370] Trial 15 finished with value: -0.8517496869413392 and parameters: {'n_estimators': 1183, 'learning_rate': 0.02065918520220814, 'num_leaves': 60, 'max_depth': 7, 'min_child_samples': 37, 'subsample': 0.871928066027463, 'colsample_bytree': 0.7643652786291671, 'reg_alpha': 0.31499708835134, 'reg_lambda': 3.9837946629475116}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:40:40,469] Trial 16 finished with value: -0.8909439328039227 and parameters: {'n_estimators': 1463, 'learning_rate': 0.09265387702659139, 'num_leaves': 66, 'max_depth': 8, 'min_child_samples': 28, 'subsample': 0.750403102185309, 'colsample_bytree': 0.8784949448127753, 'reg_alpha': 1.681546148410217, 'reg_lambda': 0.0796466227788882}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:41:29,150] Trial 17 finished with value: -0.8942832648425333 and parameters: {'n_estimators': 1026, 'learning_rate': 0.07274167500128763, 'num_leaves': 51, 'max_depth': 7, 'min_child_samples': 46, 'subsample': 0.8762504003712954, 'colsample_bytree': 0.6128640302227175, 'reg_alpha': 5.777321048918315, 'reg_lambda': 3.548596085029569}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:42:10,225] Trial 18 finished with value: -0.8787323574394365 and parameters: {'n_estimators': 925, 'learning_rate': 0.05345587650229533, 'num_leaves': 68, 'max_depth': 6, 'min_child_samples': 73, 'subsample': 0.7626831880430478, 'colsample_bytree': 0.9226311416287112, 'reg_alpha': 3.06191377982368, 'reg_lambda': 3.333104085057996}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:43:07,997] Trial 19 finished with value: -0.8708359781894662 and parameters: {'n_estimators': 784, 'learning_rate': 0.11043223170142683, 'num_leaves': 48, 'max_depth': 8, 'min_child_samples': 23, 'subsample': 0.9184899588876969, 'colsample_bytree': 0.8585870808959771, 'reg_alpha': 1.4793473118174898, 'reg_lambda': 1.0598110296010446}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:43:53,971] Trial 20 finished with value: -0.86942080952964 and parameters: {'n_estimators': 1231, 'learning_rate': 0.03198817107229693, 'num_leaves': 95, 'max_depth': 5, 'min_child_samples': 44, 'subsample': 0.7029908366274759, 'colsample_bytree': 0.7845189473132667, 'reg_alpha': 5.684910175356514, 'reg_lambda': 4.543807934600782}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:44:40,221] Trial 21 finished with value: -0.8444930439022277 and parameters: {'n_estimators': 1074, 'learning_rate': 0.021364810558167035, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 34, 'subsample': 0.8644343634056113, 'colsample_bytree': 0.9132246111735821, 'reg_alpha': 2.274416177280676, 'reg_lambda': 7.3806535962416735}. Best is trial 14 with value: -0.8427647581068584.\n",
            "[I 2025-11-02 17:45:39,549] Trial 22 finished with value: -0.8378931001409523 and parameters: {'n_estimators': 1085, 'learning_rate': 0.021950363572199053, 'num_leaves': 40, 'max_depth': 6, 'min_child_samples': 27, 'subsample': 0.8458252807467358, 'colsample_bytree': 0.9259091409399249, 'reg_alpha': 3.304516363792839, 'reg_lambda': 7.529035630502902}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:46:30,722] Trial 23 finished with value: -0.848622940386599 and parameters: {'n_estimators': 953, 'learning_rate': 0.04382329177751171, 'num_leaves': 36, 'max_depth': 6, 'min_child_samples': 28, 'subsample': 0.8495512010344531, 'colsample_bytree': 0.9390560557853252, 'reg_alpha': 3.6858610303603645, 'reg_lambda': 7.382567112921262}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:47:55,448] Trial 24 finished with value: -0.8412817353459072 and parameters: {'n_estimators': 1082, 'learning_rate': 0.03032349619192524, 'num_leaves': 22, 'max_depth': 8, 'min_child_samples': 24, 'subsample': 0.6022892692105742, 'colsample_bytree': 0.9998154370466419, 'reg_alpha': 1.4028858037555818, 'reg_lambda': 5.918175189113525}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:49:35,432] Trial 25 finished with value: -0.8673137752149965 and parameters: {'n_estimators': 1193, 'learning_rate': 0.0656475071752735, 'num_leaves': 22, 'max_depth': 8, 'min_child_samples': 20, 'subsample': 0.6147820216964964, 'colsample_bytree': 0.9994383621500567, 'reg_alpha': 1.1879531215617514, 'reg_lambda': 5.941691203114431}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:50:40,190] Trial 26 finished with value: -0.8790680388729438 and parameters: {'n_estimators': 805, 'learning_rate': 0.048573228824222395, 'num_leaves': 30, 'max_depth': 9, 'min_child_samples': 45, 'subsample': 0.9150796203206345, 'colsample_bytree': 0.9969585080766167, 'reg_alpha': 0.659428205318142, 'reg_lambda': 5.6113570738098355}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:52:19,727] Trial 27 finished with value: -0.8542913858470875 and parameters: {'n_estimators': 1476, 'learning_rate': 0.03287309015562926, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.8350851548439334, 'colsample_bytree': 0.9515147109136219, 'reg_alpha': 5.3562846233710655, 'reg_lambda': 6.8051414251448765}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:53:45,450] Trial 28 finished with value: -0.9065355264578735 and parameters: {'n_estimators': 1139, 'learning_rate': 0.07984320949778288, 'num_leaves': 38, 'max_depth': 10, 'min_child_samples': 65, 'subsample': 0.6041290028533796, 'colsample_bytree': 0.9436174480601502, 'reg_alpha': 1.8354042785273719, 'reg_lambda': 8.567380994770303}. Best is trial 22 with value: -0.8378931001409523.\n",
            "[I 2025-11-02 17:55:12,962] Trial 29 finished with value: -0.84401855618141 and parameters: {'n_estimators': 1279, 'learning_rate': 0.029369880910866397, 'num_leaves': 27, 'max_depth': 8, 'min_child_samples': 25, 'subsample': 0.703522088370182, 'colsample_bytree': 0.8256176165242585, 'reg_alpha': 3.151758058289006, 'reg_lambda': 3.180924827731137}. Best is trial 22 with value: -0.8378931001409523.\n",
            "Best LGB params: {'n_estimators': 1085, 'learning_rate': 0.021950363572199053, 'num_leaves': 40, 'max_depth': 6, 'min_child_samples': 27, 'subsample': 0.8458252807467358, 'colsample_bytree': 0.9259091409399249, 'reg_alpha': 3.304516363792839, 'reg_lambda': 7.529035630502902}\n",
            "Training optimized LightGBM...\n",
            "Training enhanced XGBoost...\n",
            "Training enhanced CatBoost...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3035470380.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Train optimized models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_optimized_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_optuna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3035470380.py\u001b[0m in \u001b[0;36mcreate_optimized_models\u001b[0;34m(X_train, y_train, X_test, use_optuna)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     )\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5874\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m             train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2396\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m                 \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0m_check_param_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_params_type_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0m_check_train_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_fraction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip all heavy training - just use the optimized parameters we found!\n",
        "print(\"âš¡ USING OPTUNA RESULTS - No retraining needed!\")\n",
        "\n",
        "# Use the BEST parameters Optuna already found\n",
        "best_lgb_params = {\n",
        "    'n_estimators': 1085,\n",
        "    'learning_rate': 0.021950363572199053,\n",
        "    'num_leaves': 40,\n",
        "    'max_depth': 6,\n",
        "    'min_child_samples': 27,\n",
        "    'subsample': 0.8458252807467358,\n",
        "    'colsample_bytree': 0.9259091409399249,\n",
        "    'reg_alpha': 3.304516363792839,\n",
        "    'reg_lambda': 7.529035630502902\n",
        "}\n",
        "\n",
        "print(\"ðŸ† Using OPTIMIZED LightGBM params (MAE: 0.8379)\")\n",
        "\n",
        "# Train ONLY the optimized LightGBM (30 seconds)\n",
        "optimized_lgb = LGBMRegressor(**best_lgb_params, random_state=42, n_jobs=-1, verbose=-1)\n",
        "optimized_lgb.fit(X_train_combined, y_train)\n",
        "\n",
        "# Quick predictions\n",
        "final_predictions = optimized_lgb.predict(X_test_combined)\n",
        "final_predictions = np.maximum(final_predictions, 0.1)  # Ensure positive\n",
        "\n",
        "print(f\"âœ… Optimized model trained in 30 seconds!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36_RxOWAlzzZ",
        "outputId": "263b4f84-468a-4ad8-d793-a75b93d6aa29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ USING OPTUNA RESULTS - No retraining needed!\n",
            "ðŸ† Using OPTIMIZED LightGBM params (MAE: 0.8379)\n",
            "âœ… Optimized model trained in 30 seconds!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create final submission immediately\n",
        "final_submission = pd.DataFrame({\n",
        "    'patient_id': test_patient['patient_id'],\n",
        "    'predicted_risk_score': final_predictions\n",
        "})\n",
        "\n",
        "print(f\"ðŸ“Š FINAL OPTIMIZED Predictions:\")\n",
        "print(f\"Min: {final_predictions.min():.4f}\")\n",
        "print(f\"Max: {final_predictions.max():.4f}\")\n",
        "print(f\"Mean: {final_predictions.mean():.4f}\")\n",
        "print(f\"Std: {final_predictions.std():.4f}\")\n",
        "\n",
        "# Save submission\n",
        "final_submission.to_csv('Prediction_OPTIMIZED_FAST.csv', index=False)\n",
        "final_submission.to_csv('Prediction.csv', index=False)\n",
        "\n",
        "print(\"âœ… OPTIMIZED Prediction.csv saved in 2 minutes!\")\n",
        "print(f\"ðŸ“Š Submission shape: {final_submission.shape}\")\n",
        "print(final_submission.head())\n",
        "\n",
        "# Success report\n",
        "print(\"\\nðŸŽ‰ SUPER FAST OPTIMIZATION COMPLETE!\")\n",
        "print(\"=\"*40)\n",
        "print(f\"âš¡ TOTAL TIME: 2 minutes\")\n",
        "print(f\"ðŸ† EXPECTED MAE: ~0.838 (Excellent!)\")\n",
        "print(f\"ðŸ”¥ USED BEST OPTUNA PARAMS\")\n",
        "print(f\"âœ… READY FOR SUBMISSION!\")\n",
        "print(\"=\"*40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdcrZ4Hwl5_O",
        "outputId": "ad3767e1-1a2a-45c2-d95e-b45a78e9a521"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š FINAL OPTIMIZED Predictions:\n",
            "Min: 0.1000\n",
            "Max: 22.6974\n",
            "Mean: 1.7041\n",
            "Std: 1.9099\n",
            "âœ… OPTIMIZED Prediction.csv saved in 2 minutes!\n",
            "ðŸ“Š Submission shape: (2001, 2)\n",
            "   patient_id  predicted_risk_score\n",
            "0         276                  0.57\n",
            "1         309                  0.54\n",
            "2         327                  0.75\n",
            "3         333                  2.47\n",
            "4         344                  1.89\n",
            "\n",
            "ðŸŽ‰ SUPER FAST OPTIMIZATION COMPLETE!\n",
            "========================================\n",
            "âš¡ TOTAL TIME: 2 minutes\n",
            "ðŸ† EXPECTED MAE: ~0.838 (Excellent!)\n",
            "ðŸ”¥ USED BEST OPTUNA PARAMS\n",
            "âœ… READY FOR SUBMISSION!\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFRTz5U7mGR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}